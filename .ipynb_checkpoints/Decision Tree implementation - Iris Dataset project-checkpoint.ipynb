{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the iris data\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data into Pandas Data Frame\n",
    "df = pd.DataFrame(iris.data)\n",
    "df.columns = ['sl', 'sw', 'pl', 'pw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label function to find label for a value of a particular feature\n",
    "# if value < (df[feature_name].min() + df[feature_name].mean())/2 then it is assigned 'a' label\n",
    "# if (df[feature_name].min() + df[feature_name].mean())/2 <= value < df[feature_name].mean() then it is assigned 'b' label\n",
    "# if df[feature_name].mean() <= value < (df[feature_name].max() + df[feature_name].mean())/2 then it is assigned 'c' label\n",
    "# if (df[feature_name].max() + df[feature_name].mean())/2 <= value then it is assigned 'd' label\n",
    "def label(val, *boundaries):\n",
    "    if val<boundaries[0]:\n",
    "        return 'a'\n",
    "    elif val<boundaries[1]:\n",
    "        return 'b'\n",
    "    elif val<boundaries[2]:\n",
    "        return 'c'\n",
    "    else:\n",
    "        return 'd'\n",
    "    \n",
    "def toLabel(df, feature_name):\n",
    "    second = df[feature_name].mean()\n",
    "    first = (df[feature_name].min() + second)/2\n",
    "    third = (df[feature_name].max() + second)/2\n",
    "    return df[feature_name].apply(label, args=(first, second, third))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all columns to labelled data\n",
    "df['sl'] = toLabel(df, 'sl')\n",
    "df['sw'] = toLabel(df, 'sw')\n",
    "df['pl'] = toLabel(df, 'pl')\n",
    "df['pw'] = toLabel(df, 'pw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sl sw pl pw\n",
       "0  b  c  a  a\n",
       "1  a  b  a  a\n",
       "2  a  c  a  a\n",
       "3  a  c  a  a\n",
       "4  a  c  a  a\n",
       "5  b  d  a  a\n",
       "6  a  c  a  a\n",
       "7  a  c  a  a\n",
       "8  a  b  a  a\n",
       "9  a  c  a  a"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the labelled data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'sl', 1: 'sw', 2: 'pl', 3: 'pw'}\n",
      "{0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n"
     ]
    }
   ],
   "source": [
    "x = df.values                                        # x is actually train_x\n",
    "y = iris.target                                      # y is actually train_y\n",
    "features = np.arange(x.shape[1])\n",
    "dictionary_feature = {}                              # creating a dictionary of features of train_x\n",
    "for f in features:\n",
    "    dictionary_feature[f] = df.columns[f]\n",
    "print(dictionary_feature)\n",
    "classes = np.arange(len(set(y)))\n",
    "dictionary_class = {}                                # creating a dictionary of classes in train_y\n",
    "for c in classes:\n",
    "    dictionary_class[c] = iris.target_names[c]\n",
    "print(dictionary_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_ratio(x, y, f):                                               # gain_ratio finction for calculating gain ratio after splitting on feature f\n",
    "    entropy_upper = 0                                                  # entropy_upper for parent node                                      \n",
    "    for c in set(y):\n",
    "        num = (y == c).sum()\n",
    "        den = len(y)\n",
    "        if(num == 0):\n",
    "            continue\n",
    "        entropy_upper += -(num/den)*(m.log(num/den, 2))                # calculating entropy of parent node\n",
    "    \n",
    "    entropy_lower = 0                                                  # entropy_lower for child node(s)\n",
    "    for l in set(x[:,f]):                                              # l are the labels in a feature of x\n",
    "        entropy_lower_labelwise = 0                                    # entropy_lower_labelwise is for calculating entropy of individual label ['a', 'b', 'c', 'd']\n",
    "        for c in set(y):\n",
    "            num = (np.logical_and(x[:,f] == l, y==c) == True).sum()\n",
    "            den = (x[:,f] == l).sum()\n",
    "            if(num == 0):\n",
    "                continue\n",
    "            entropy_lower_labelwise += -(num/den)*(m.log(num/den, 2))  \n",
    "        entropy_lower_labelwise *= ((x[:,f] == l).sum())/len(x[:,f])   # calculating weighted average of entopy_lower_labelwise\n",
    "        entropy_lower += entropy_lower_labelwise                       # adding weighted average weighted average to entropy_lower\n",
    "    information_gain = entropy_upper - entropy_lower                   # calculating information gain\n",
    "    \n",
    "    split_info = 0                                                     # split_info is calculating split information after splitting parent node into child node(s)\n",
    "    for l in set(x[:, f]):\n",
    "        num = (x[:, f] == l).sum()\n",
    "        den = len(x[:, f])\n",
    "        if(num == 0):\n",
    "            continue\n",
    "        split_info += -(num/den)*(m.log(num/den, 2))\n",
    "    \n",
    "    if split_info == 0.0:                                              # if the parent node is splitted into only one single child node, then split info will be zero\n",
    "        gain_ratio = 0.0                                               # and split_info will be zero. This will give nan value. So instead making gain_r zero\n",
    "    else:\n",
    "        gain_ratio = information_gain/split_info                       # gain_r for calculating gain ratio\n",
    "    \n",
    "    return gain_ratio                                                  # returning the calculated gain ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(x, y, features, level):                              # decision_tree function for forming a decision tree based on criterion='gain-ratio'\n",
    "    print(\"level :\", level)                                            # printing the level\n",
    "    if len(set(y)) == 1:                                               # pure node condition \n",
    "        c = set(y).pop()\n",
    "        print(\"Count of\", dictionary_class[c],\" =\", len(y))            # printing the only class in the pure node and its count\n",
    "        print(\"Current Entropy : 0.0\")                                 # entropy of pure node is always 0.0\n",
    "        print(\"Reached Leaf Node\")                                     # printing that this node is leaf node\n",
    "        return                                                          \n",
    "    \n",
    "    if len(features) == 0:                                             # if there is no feature left to split upon then this condition will be true\n",
    "        entropy = 0                                                    # entropy for calculating the entropy of node\n",
    "        for c in set(y):\n",
    "            print(\"Count of\", dictionary_class[c],\" =\", (y==c).sum())  # printing the classes in the node and their counts\n",
    "            num = (y==c).sum()\n",
    "            den = len(y)\n",
    "            if num == 0:\n",
    "                continue\n",
    "            entropy = -(num/den)*m.log(num/den, 2)\n",
    "        print(\"Current Entropy :\", entropy)                            # printing the entropy\n",
    "        print(\"Reached leaf Node\")                                     # printing that this node is leaf node\n",
    "        return\n",
    "                                                                       # if the above two condition are false then the code below will get executed\n",
    "    entropy = 0                                                        # entropy for calculating the entropy of node\n",
    "    for c in set(y):\n",
    "        print(\"Count of\", dictionary_class[c],\" =\", (y==c).sum())      # printing the classes in the node and their counts   \n",
    "        num = (y==c).sum()\n",
    "        den = len(y)\n",
    "        if num == 0:\n",
    "            continue\n",
    "        entropy = -(num/den)*m.log(num/den, 2)\n",
    "    print(\"Current Entropy :\", entropy)                                # printing current entropy\n",
    "    max_gain = -1000                                                   # max_gain for finding the maximum gain when splitting on a number of features\n",
    "    best_feature = -1                                                  # best_feature for finding the best feature to split upon\n",
    "    for f in features:                                                 # this for loop will find the best feature with max gain_ratio\n",
    "        if(max_gain<=gain_ratio(x, y, f)):\n",
    "            max_gain = gain_ratio(x, y, f)\n",
    "            best_feature = f\n",
    "    print(\"Splitting on\", dictionary_feature[best_feature],            # printing on which feature(the best one) the node is splitted\n",
    "          \" with gain ratio\",max_gain)                                 # with max gain ratio\n",
    "    index_of_best_feature = np.where(features == best_feature)         # index_of_best_feature for finding index of best feature\n",
    "    #print(index_of_best_feature)\n",
    "    features = np.delete(features, index_of_best_feature)              # removing the best feature from 'features'\n",
    "    #print(features)\n",
    "    level += 1                                                         # increasing the level by 1\n",
    "    for l in set(x[:, best_feature]):                                  # this for loop is for making recursive calls on labels present in the best feature\n",
    "        indexes = np.where(x[:, best_feature] == l)\n",
    "        #print(indexes)\n",
    "        df = pd.DataFrame(x)\n",
    "        x_new = (df.iloc[indexes]).values                              # x_new contains that rows with the selected best_feature having only a particular label \n",
    "        df = pd.DataFrame(y)                                        \n",
    "        y_new = ((df.iloc[indexes]).values).ravel()                    # y_new corresponding to xnew and is converted to 1D using ravel\n",
    "        print()\n",
    "        decision_tree(x_new, y_new, features, level)                   # recursive call to decision_tree with x_new, y_new, features(selected best feature is excluded) and level(which was increased to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level : 0\n",
      "Count of setosa  = 50\n",
      "Count of versicolor  = 50\n",
      "Count of virginica  = 50\n",
      "Current Entropy : 0.5283208335737187\n",
      "Splitting on pw  with gain ratio 0.699638203622209\n",
      "\n",
      "level : 1\n",
      "Count of versicolor  = 10\n",
      "Current Entropy : 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "level : 1\n",
      "Count of versicolor  = 40\n",
      "Count of virginica  = 16\n",
      "Current Entropy : 0.5163871205878868\n",
      "Splitting on pl  with gain ratio 0.4334099495621066\n",
      "\n",
      "level : 2\n",
      "Count of versicolor  = 39\n",
      "Count of virginica  = 8\n",
      "Current Entropy : 0.4348236343281085\n",
      "Splitting on sl  with gain ratio 0.12674503775809332\n",
      "\n",
      "level : 3\n",
      "Count of virginica  = 1\n",
      "Current Entropy : 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "level : 3\n",
      "Count of versicolor  = 23\n",
      "Count of virginica  = 7\n",
      "Current Entropy : 0.48989165716188005\n",
      "Splitting on sw  with gain ratio 0.07092036405148876\n",
      "\n",
      "level : 4\n",
      "Count of versicolor  = 3\n",
      "Count of virginica  = 1\n",
      "Current Entropy : 0.5\n",
      "Reached leaf Node\n",
      "\n",
      "level : 4\n",
      "Count of versicolor  = 6\n",
      "Current Entropy : 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "level : 4\n",
      "Count of versicolor  = 14\n",
      "Count of virginica  = 6\n",
      "Current Entropy : 0.5210896782498619\n",
      "Reached leaf Node\n",
      "\n",
      "level : 3\n",
      "Count of versicolor  = 2\n",
      "Current Entropy : 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "level : 3\n",
      "Count of versicolor  = 14\n",
      "Current Entropy : 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "level : 2\n",
      "Count of virginica  = 8\n",
      "Current Entropy : 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "level : 2\n",
      "Count of versicolor  = 1\n",
      "Current Entropy : 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "level : 1\n",
      "Count of virginica  = 34\n",
      "Current Entropy : 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "level : 1\n",
      "Count of setosa  = 50\n",
      "Current Entropy : 0.0\n",
      "Reached Leaf Node\n"
     ]
    }
   ],
   "source": [
    "level = 0                                # initliazing the variable 'label' with 0 as tree start from level 0\n",
    "decision_tree(x, y, features, level)     # call to decision_tree function for forming decision tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
